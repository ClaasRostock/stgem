{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "from stgem.algorithm.ogan.mlm import GeneratorNetwork\n",
    "from stgem.generator import STGEM, STGEMResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb119d45",
   "metadata": {},
   "source": [
    "Here we setup identifiers for both validation data and the actual data from a\n",
    "single benchmark. Edit the path as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364eb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"problems\", \"arch-comp-2021\")\n",
    "validation_identifier = \"AT1_validation\"\n",
    "data_identifier = \"AT1_data\"\n",
    "\n",
    "validation_data_file = os.path.join(path, \"{}.npy.gz\".format(validation_identifier))\n",
    "data_file = os.path.join(path, \"{}.npy.gz\".format(data_identifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3ed08",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2cc5b8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a data file produced by\n",
    "`problems/arch-comp-2021/create_validation_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b187a92",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_repository = STGEMResult.restore_from_file(validation_data_file).step_results[0].test_repository\n",
    "X_v, _, Y_v = test_repository.get()\n",
    "X_v = np.array([x.inputs for x in X_v])\n",
    "Y_v = np.array(Y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d808636",
   "metadata": {},
   "source": [
    "# Load Benchmark Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d0b1b",
   "metadata": {},
   "source": [
    "The current code assumes that OGAN algorithm was used as the second step. The\n",
    "remaining code does not work correctly with other algorithms. In addition, we\n",
    "assume that there is a single objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_loss(result, idx):\n",
    "    \"\"\"Returns the OGAN model indicated by the given index and the\n",
    "    discriminator loss function.\"\"\"\n",
    "\n",
    "    # We assume a single objective.\n",
    "    objective_idx = 0\n",
    "\n",
    "    # Load a model.\n",
    "    try:\n",
    "        model_skeleton = result.step_results[1].models[idx][objective_idx]\n",
    "    except IndexError:\n",
    "        raise Exception(\"Unable to load model with index {}. Either the index is out of bounds or the replica data file does not contain saved models.\")\n",
    "\n",
    "    # TODO: remove these when done\n",
    "    #model_skeleton.parameters[\"discriminator_mlm_parameters\"][\"convolution_activation\"] = \"leaky_relu\"\n",
    "    #del model_skeleton.parameters[\"discriminator_mlm_parameters\"][\"hidden_activation\"]\n",
    "    model_skeleton.parameters[\"generator_mlm_parameters\"][\"hidden_activation\"] = \"leaky_relu\"\n",
    "\n",
    "    # Get the loss of the model on the validation data.\n",
    "    from stgem.sut import SearchSpace\n",
    "    search_space = SearchSpace()\n",
    "    search_space.input_dimension = model_skeleton.input_dimension\n",
    "\n",
    "    from stgem.algorithm.ogan.model import OGAN_Model\n",
    "    model = OGAN_Model.setup_from_skeleton(model_skeleton, search_space, torch.device(\"cpu\"))\n",
    "\n",
    "    loss = lambda X, Y: model.lossD(torch.from_numpy(X).float(), torch.from_numpy(Y).float()).cpu().detach().numpy()\n",
    "\n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7673ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_idx = 0 # Which objective is used.\n",
    "model_idx = 0 # Which model to load from the replica data.\n",
    "result = STGEMResult.restore_from_file(data_file)\n",
    "model, loss = get_model_loss(result, model_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68732e3e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model Predictions on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba37ea0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_predictions = model.predict_objective(X_v)\n",
    "print(\"Model loss on complete validation data:\")\n",
    "print(loss(model_predictions, Y_v))\n",
    "print()\n",
    "print(\"Prediction: Ground truth:\")\n",
    "for i, x in enumerate(X_v):\n",
    "    print(model.predict_objective(x.reshape(1, -1))[0,0], Y_v[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744df572",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# All Model Predictions on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58816e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "no_of_models = 225 # How many models were saved.\n",
    "for idx in range(0, no_of_models):\n",
    "    _model, _loss = get_model_loss(result, idx)\n",
    "    model_predictions = _model.predict_objective(X_v)\n",
    "    value = loss(model_predictions, Y_v)\n",
    "    print(\"Model = {}, loss on validation = {}\".format(idx, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a76a37c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plot Loss of Final Model over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004a3c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = model.train_settings[\"discriminator_epochs\"]\n",
    "step_tests = result.step_results[1].parameters[\"tests_executed\"]\n",
    "data = [result.test_repository.performance(i).obtain(\"discriminator_loss\")[objective_idx] for i in step_tests]\n",
    "data = np.array(data).reshape(-1)\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1, epochs + 1), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de78e22b",
   "metadata": {},
   "source": [
    "# Train New Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea4cde",
   "metadata": {},
   "source": [
    "Here we train a new discriminator based on the replica test repository data.\n",
    "Its performance is measured by computing loss on the validation data. The\n",
    "resulting discriminator is found in the variable `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eff973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_on_validation(model):\n",
    "    model_predictions = model.predict_objective(X_v)\n",
    "    return model.lossD(torch.from_numpy(model_predictions).float(), torch.from_numpy(Y_v).float()).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30734804",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _, Y = result.test_repository.get()\n",
    "X = np.array([x.inputs for x in X])\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Setup discriminator parameters.\n",
    "#model.parameters[\"optimizer\"] = \"Adam\"\n",
    "#model.train_settings[\"discriminator_epochs\"] = 30\n",
    "#model.parameters[\"discriminator_lr\"] = 0.005\n",
    "#model.parameters[\"discriminator_mlm_parameters\"][\"hidden_neurons\"] = [128,128,128]\n",
    "#model.parameters[\"discriminator_mlm_parameters\"][\"feature_maps\"] = [16,16]\n",
    "#model.parameters[\"discriminator_mlm_parameters\"][\"kernel_sizes\"] = [[2,2],[2,2]]\n",
    "#model.parameters[\"discriminator_mlm_parameters\"][\"dense_neurons\"] = 128\n",
    "#model.parameters[\"discriminator_mlm_parameters\"][\"convolution_activation\"] = \"leaky_relu\"\n",
    "\n",
    "model.reset()\n",
    "\n",
    "validation_losses = []\n",
    "epochs = model.train_settings[\"discriminator_epochs\"]\n",
    "for i in range(epochs):\n",
    "    model.train_with_batch(X, Y, train_settings=model.parameters[\"train_settings\"])\n",
    "    validation_losses.append(loss_on_validation(model))\n",
    "    print(\"epoch = {:>2}, validation loss = {}\".format(i + 1, validation_losses[-1]))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1, epochs + 1), validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15e2ec",
   "metadata": {},
   "source": [
    "# Train New Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342aa436",
   "metadata": {},
   "source": [
    "Here we train a new generator on the discriminator found in `model`. We report\n",
    "the training losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss_on_batch(model, batch_size):\n",
    "    \"\"\"Finds the discriminator loss on a random batch of inputs.\"\"\"\n",
    "\n",
    "    noise = 2*torch.rand(batch_size, model.modelD.input_shape) - 1\n",
    "    inputs = noise.float().to(\"cpu\")\n",
    "\n",
    "    fake_label = torch.zeros(size=(batch_size, 1)).to(\"cpu\")\n",
    "\n",
    "    outputs = model.modelD(inputs)\n",
    "    loss = model.lossD(outputs, fake_label)\n",
    "\n",
    "    return loss.detach().cpu().item()\n",
    "\n",
    "def generator_loss_on_batch(model, batch_size):\n",
    "    \"\"\"Finds the discriminator loss on a random batch of noise fed through the\n",
    "    generator.\"\"\"\n",
    "\n",
    "    noise = 2*torch.rand(batch_size, model.modelG.input_shape) - 1\n",
    "    inputs = noise.float().to(\"cpu\")\n",
    "\n",
    "    fake_label = torch.zeros(size=(batch_size, 1)).to(\"cpu\")\n",
    "\n",
    "    outputs = model.modelD(model.modelG(inputs))\n",
    "    loss = model.lossG(outputs, fake_label)\n",
    "\n",
    "    return loss.detach().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([])\n",
    "Y = np.array([])\n",
    "\n",
    "discriminator_epochs_saved = model.parameters[\"train_settings\"][\"discriminator_epochs\"]\n",
    "epochs_saved = model.parameters[\"train_settings\"][\"epochs\"]\n",
    "model.parameters[\"train_settings\"][\"epochs\"] = 1\n",
    "model.parameters[\"train_settings\"][\"discriminator_epochs\"] = 0\n",
    "\n",
    "# Setup generator parameters.\n",
    "#model.parameters[\"noise_batch_size\"] = 12000\n",
    "#model.parameters[\"generator_lr\"] = 0.0001\n",
    "#model.parameters[\"generator_mlm_parameters\"][\"noise_dim\"] = 20\n",
    "#model.parameters[\"generator_mlm_parameters\"][\"hidden_neurons\"] = [128,128,128]\n",
    "#model.parameters[\"generator_mlm_parameters\"][\"hidden_neurons\"] = [64,64]\n",
    "\n",
    "model.modelG = GeneratorNetwork(**model.generator_mlm_parameters)\n",
    "model.optimizerG = torch.optim.Adam(model.modelG.parameters(), lr=model.generator_lr, betas=model.generator_betas)\n",
    "\n",
    "model.parameters[\"train_settings\"][\"discriminator_epochs\"] = discriminator_epochs_saved\n",
    "model.parameters[\"train_settings\"][\"epochs\"] = epochs_saved\n",
    "\n",
    "model.train_with_batch(X, Y, train_settings=model.parameters[\"train_settings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "# TODO: This needs to be updated to use the latest performance records. What does this do?\n",
    "A = model.perf.histories[\"generator_loss\"][-1][0]\n",
    "B = model.perf.histories[\"generator_loss\"][-1][-1]\n",
    "print(\"training loss: {} -> {}\".format(A, B))\n",
    "print(\"noise batch loss: {}\".format(generator_loss_on_batch(model, batch_size)))\n",
    "print(\"discriminator batch loss: {}\".format(discriminator_loss_on_batch(model, batch_size)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

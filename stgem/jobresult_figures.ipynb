{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_job_result(file_name):\n",
    "    with open(file_name, mode=\"rb\") as f:\n",
    "        jr = pickle.load(f)\n",
    "    \n",
    "    jr.N_models = len(jr.description[\"objective_func\"])\n",
    "    \n",
    "    return jr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "jr = load_job_result(\"output_0_0.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_minimum_objective(jr):\n",
    "    _, dataY = jr.test_repository.get(jr.test_suite)\n",
    "    dataY = np.asarray(dataY)\n",
    "    component_minima = [[] for i in range(dataY.shape[1])]\n",
    "    total_minima = []\n",
    "    for output in dataY:\n",
    "        for i in range(len(output)):\n",
    "            if len(component_minima[i]) == 0 or output[i] < component_minima[i][-1]:\n",
    "                component_minima[i].append(output[i])\n",
    "            else:\n",
    "                component_minima[i].append(component_minima[i][-1])\n",
    "                \n",
    "        min_obj = np.min(output)\n",
    "        if len(total_minima) == 0 or min_obj < total_minima[-1]:\n",
    "            total_minima.append(min_obj)\n",
    "        else:\n",
    "            total_minima.append(total_minima[-1])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, len(output) + 1, sharex=True, sharey=True, figsize=(10*len(output), 10))\n",
    "    for i in range(len(output)):\n",
    "        axs[i].plot(component_minima[i])\n",
    "        axs[i].set_title(\"Component {} minimum\".format(i+1))\n",
    "    axs[-1].plot(total_minima)\n",
    "    axs[-1].set_title(\"Overall minimum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_losses(jr, model):\n",
    "    perf = jr.model_performance[model]\n",
    "    data_D = perf.get_history(\"discriminator_loss\")\n",
    "    data_G = perf.get_history(\"generator_loss\")\n",
    "    rows = len(data_D)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, 2, sharex=True, figsize=(10, 10*rows))\n",
    "    for r in range(rows):\n",
    "        idx = (r,0) if rows > 1 else 0\n",
    "        axs[idx].plot(data_D[r])\n",
    "        axs[idx].set_title(\"Model reset {} discriminator l.\".format(r))\n",
    "        idx = (r,1) if rows > 1 else 1\n",
    "        axs[idx].plot(data_G[r])\n",
    "        axs[idx].set_title(\"Model reset {} generator l.\".format(r))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_losses(jr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_minimum_objective(jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_falsified_at(jr):\n",
    "    _, outputs = jr.test_repository.get(jr.test_suite)\n",
    "    outputs = np.asarray(outputs)\n",
    "    \n",
    "    falsified = False\n",
    "    for i in range(outputs.shape[0]):\n",
    "        if np.min(outputs[i,:]) == 0:\n",
    "            falsified = True\n",
    "            break\n",
    "    \n",
    "    return i + 1 if falsified else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_falsifications(jrs):\n",
    "    return [first_falsified_at(jr) for jr in jrs]\n",
    "\n",
    "def falsification_rate(jrs):\n",
    "    return sum(1 for jr in jrs if first_falsified_at(jr) > 0)/len(jrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(2):\n",
    "    jrs = []\n",
    "    for j in range(0, 10):\n",
    "        jrs.append(load_job_result(\"job_{}_{}.pickle\".format(i, j)))\n",
    "    models.append(jrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    print(\"Model {}:\".format(i))\n",
    "    print(\"  falsifications: {}\".format(first_falsifications(models[i])))\n",
    "    print(\"  falsification rate: {}\".format(falsification_rate(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-settle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
